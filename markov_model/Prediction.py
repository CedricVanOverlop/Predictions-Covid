"""
IMPL√âMENTATION CORRECTE SELON VOTRE RAISONNEMENT MATH√âMATIQUE
Suit exactement : X‚Éó(t+1) = A ¬∑ X‚Éó(t) + Œµ‚Éó(t)
Avec A_finale = (1 - Œ±) ¬∑ A_brute + Œ± ¬∑ (A_brute ‚äô G)
"""

import json
import os
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from colorama import init, Fore

init(autoreset=True)


class MatrixMarkovModel:
    """
    Impl√©mentation exacte de votre mod√®le math√©matique :
    X‚Éó(t+1) = A ¬∑ X‚Éó(t) avec contraintes g√©ographiques
    """
    
    def __init__(self, smoothed_data_file: str = "data/smoothed_data.json", 
                 geographic_weights_file: str = "data/geographic_weights.json"):
        """
        Initialise selon votre mod√®le math√©matique
        """
        print("üî¨ Initialisation du mod√®le de Markov selon le raisonnement math√©matique...")
        
        # Chargement des donn√©es
        self.smoothed_data = self._load_smoothed_data(smoothed_data_file)
        self.geographic_weights = self._load_geographic_weights(geographic_weights_file)
        
        # Communes (19 communes de Bruxelles)
        self.communes = sorted(list(self.geographic_weights.keys()))
        self.n_communes = len(self.communes)
        self.commune_to_index = {commune: i for i, commune in enumerate(self.communes)}
        
        # Mod√®le selon votre approche
        self.transition_matrix = None  # A_finale
        self.geographic_matrix = self._build_geographic_matrix_G()  # Matrice G
        
        print(f"‚úÖ Mod√®le math√©matique initialis√© : {self.n_communes} communes")
        print("üìã Suivant : X‚Éó(t+1) = A ¬∑ X‚Éó(t) + Œµ‚Éó(t)")
    
    def _load_smoothed_data(self, file_path: str) -> Dict:
        """Charge les donn√©es liss√©es Savitzky-Golay"""
        try:
            with open(file_path, 'r', encoding='utf8') as f:
                data = json.load(f)
            return data["data"] if "data" in data else data
        except FileNotFoundError:
            print(Fore.RED + f"‚ùå Fichier non trouv√© : {file_path}")
            raise
    
    def _load_geographic_weights(self, file_path: str) -> Dict:
        """Charge les poids g√©ographiques (r√©sultats Dijkstra)"""
        try:
            with open(file_path, 'r', encoding='utf8') as f:
                data = json.load(f)
            return data["weights"] if "weights" in data else data
        except FileNotFoundError:
            print(Fore.RED + f"‚ùå Fichier non trouv√© : {file_path}")
            raise
    
    def _build_geographic_matrix_G(self) -> np.ndarray:
        """
        Construit la matrice G selon votre sp√©cification :
        G[i,j] = influence g√©ographique de commune i sur commune j
        Normalisation : Œ£‚±º G[i,j] = 1 (stochastique)
        """
        print("üó∫Ô∏è Construction de la matrice g√©ographique G...")
        
        G = np.zeros((self.n_communes, self.n_communes))
        
        # Remplissage selon les poids Dijkstra
        for i, commune_i in enumerate(self.communes):
            for j, commune_j in enumerate(self.communes):
                if commune_i in self.geographic_weights:
                    weight = self.geographic_weights[commune_i].get(commune_j, 0.0)
                    G[i, j] = weight
        
        # Normalisation stochastique (selon votre sp√©cification)
        for i in range(self.n_communes):
            row_sum = np.sum(G[i, :])
            if row_sum > 0:
                G[i, :] = G[i, :] / row_sum  # Œ£‚±º G[i,j] = 1
            else:
                G[i, i] = 1.0  # Auto-boucle si isol√©e
        
        print(f"‚úÖ Matrice G construite : stochastique avec Œ£‚±º G[i,j] = 1")
        return G
    
    def prepare_data_matrices(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        Pr√©pare X(t) et X(t+1) selon votre formulation :
        X‚Éó(t) ‚àà ‚Ñù¬π‚Åπ : vecteur d'√©tat (cas par commune au jour t)
        """
        print("üìä Pr√©paration des matrices X(t) et X(t+1)...")
        
        sorted_dates = sorted(self.smoothed_data.keys())
        n_dates = len(sorted_dates)
        
        # Matrice des donn√©es [communes √ó temps]
        data_matrix = np.zeros((self.n_communes, n_dates))
        
        for t, date in enumerate(sorted_dates):
            for i, commune in enumerate(self.communes):
                if commune in self.smoothed_data[date]:
                    value = float(self.smoothed_data[date][commune])
                    data_matrix[i, t] = max(0, value)  # ·ªπ·µ¢(t) ‚àà ‚Ñù‚Å∫
                else:
                    data_matrix[i, t] = 0.0
        
        # X(t) et X(t+1) selon votre formulation
        X_t = data_matrix[:, :-1]   # [19 √ó (T-1)]
        X_t1 = data_matrix[:, 1:]   # [19 √ó (T-1)]
        
        print(f"‚úÖ Matrices pr√©par√©es : X(t) et X(t+1) forme {X_t.shape}")
        print(f"üìÖ P√©riode d'entra√Ænement : {sorted_dates[0]} ‚Üí {sorted_dates[-1]}")
        
        return X_t, X_t1
    
    def estimate_A_brute_by_least_squares(self, X_t: np.ndarray, X_t1: np.ndarray) -> np.ndarray:
        """
        Estimation de A_brute par moindres carr√©s selon votre formulation :
        
        min ||X‚Éó(t+1) - A ¬∑ X‚Éó(t)||¬≤
        
        Solution analytique :
        A = X(t+1) ¬∑ X(t)·µÄ ¬∑ (X(t) ¬∑ X(t)·µÄ)‚Åª¬π
        """
        print("üî¢ Estimation de A_brute par moindres carr√©s...")
        print("üìê Formule : A = X(t+1) ¬∑ X(t)·µÄ ¬∑ (X(t) ¬∑ X(t)·µÄ)‚Åª¬π")
        
        try:
            # Calcul selon votre formule exacte
            X_t_transpose = X_t.T
            XtXt_T = X_t @ X_t_transpose  # X(t) ¬∑ X(t)·µÄ
            
            # R√©gularisation pour stabilit√© num√©rique
            epsilon = 1e-6
            XtXt_T_reg = XtXt_T + epsilon * np.eye(self.n_communes)
            
            # Inversion
            XtXt_T_inv = np.linalg.inv(XtXt_T_reg)
            
            # Solution analytique
            A_brute = X_t1 @ X_t_transpose @ XtXt_T_inv
            
            print(f"‚úÖ A_brute estim√©e : forme {A_brute.shape}")
            print(f"üìä Valeurs : min={np.min(A_brute):.4f}, max={np.max(A_brute):.4f}")
            
            return A_brute
            
        except np.linalg.LinAlgError:
            print(Fore.YELLOW + "‚ö†Ô∏è Probl√®me d'inversion, utilisation pseudo-inverse")
            X_t_pinv = np.linalg.pinv(X_t)
            A_brute = X_t1 @ X_t_pinv
            return A_brute
    
    def apply_geographic_constraints(self, A_brute: np.ndarray, alpha: float) -> np.ndarray:
        """
        Application des contraintes g√©ographiques selon votre formulation EXACTE :
        
        A_finale = (1 - Œ±) ¬∑ A_brute + Œ± ¬∑ (A_brute ‚äô G)
        
        o√π ‚äô est le produit de Hadamard (√©l√©ment par √©l√©ment)
        """
        print(f"üó∫Ô∏è Application des contraintes g√©ographiques (Œ±={alpha})...")
        print("üìê Formule : A_finale = (1 - Œ±) ¬∑ A_brute + Œ± ¬∑ (A_brute ‚äô G)")
        
        # Produit de Hadamard : A_brute ‚äô G
        hadamard_product = A_brute * self.geographic_matrix  # ‚äô
        
        # Combinaison lin√©aire selon votre formule
        A_finale = (1 - alpha) * A_brute + alpha * hadamard_product
        
        print(f"‚úÖ A_finale calcul√©e avec Œ±={alpha}")
        
        # V√©rification des propri√©t√©s
        eigenvalues = np.linalg.eigvals(A_finale)
        max_eigenvalue = np.max(np.abs(eigenvalues))
        
        print(f"üìä Rayon spectral : {max_eigenvalue:.4f}")
        
        if max_eigenvalue > 1.1:
            print(Fore.YELLOW + f"‚ö†Ô∏è Syst√®me potentiellement instable (Œª_max > 1)")
        
        return A_finale
    
    def evaluate_model_performance(self, A: np.ndarray, X_t: np.ndarray, X_t1: np.ndarray, 
                                 validation_split: float = 0.8) -> float:
        """
        √âvaluation selon votre crit√®re : MAE_validation(Œ±)
        """
        n_train = int(X_t.shape[1] * validation_split)
        
        if n_train < 10:  # Besoin d'assez de donn√©es
            return float('inf')
        
        # Division entra√Ænement/validation
        X_val_t = X_t[:, n_train:]
        X_val_t1 = X_t1[:, n_train:]
        
        if X_val_t.shape[1] == 0:
            return float('inf')
        
        # Pr√©dictions : X‚Éó(t+1) = A ¬∑ X‚Éó(t)
        X_pred = A @ X_val_t
        
        # Mean Absolute Error
        mae = np.mean(np.abs(X_pred - X_val_t1))
        
        return mae
    
    def train_model(self, alpha_geo_values: List[float] = None) -> Dict:
        """
        Entra√Ænement selon votre optimisation :
        Œ±* = argmin(Œ±) MAE_validation(Œ±)
        """
        if alpha_geo_values is None:
            alpha_geo_values = [0.0, 0.1, 0.3, 0.5, 0.7, 1.0]
        
        print("üéØ Entra√Ænement selon le mod√®le math√©matique...")
        print("üîç Optimisation : Œ±* = argmin(Œ±) MAE_validation(Œ±)")
        
        # Pr√©paration des donn√©es
        X_t, X_t1 = self.prepare_data_matrices()
        
        # Estimation de A_brute (√©tape 1)
        A_brute = self.estimate_A_brute_by_least_squares(X_t, X_t1)
        
        # Test de diff√©rents Œ± (√©tape 2)
        models = {}
        best_alpha = None
        best_mae = float('inf')
        
        for alpha in alpha_geo_values:
            print(f"\nüîß Test Œ± = {alpha}...")
            
            # Application des contraintes g√©ographiques
            A_finale = self.apply_geographic_constraints(A_brute, alpha)
            
            # √âvaluation
            mae = self.evaluate_model_performance(A_finale, X_t, X_t1)
            
            models[f"alpha_geo_{alpha}"] = {
                "alpha_geo": alpha,
                "transition_matrix": A_finale.tolist(),
                "mae_validation": mae
            }
            
            print(f"üìä MAE_validation({alpha}) = {mae:.3f}")
            
            # Optimisation
            if mae < best_mae:
                best_mae = mae
                best_alpha = alpha
                self.transition_matrix = A_finale
        
        if best_alpha is None:
            print(Fore.RED + "‚ùå Aucun Œ± valide trouv√©")
            return {}
        
        print(f"\nüèÜ Œ±* optimal = {best_alpha} (MAE = {best_mae:.3f})")
        
        # M√©tadonn√©es
        models["metadata"] = {
            "best_alpha_geo": best_alpha,
            "best_mae": best_mae,
            "communes": self.communes,
            "n_observations": X_t.shape[1],
            "model_formula": "X(t+1) = A * X(t)",
            "constraint_formula": "A = (1-Œ±)*A_brute + Œ±*(A_brute‚äôG)"
        }
        
        return models
    
    def predict(self, initial_state: np.ndarray, horizon_days: int = 14) -> np.ndarray:
        """
        Pr√©dictions selon votre mod√®le : X‚Éó(t+1) = A ¬∑ X‚Éó(t)
        PAS de zone d'incertitude, PAS de valeurs fixes, courbe qui monte/descend
        """
        if self.transition_matrix is None:
            raise ValueError("Mod√®le non entra√Æn√©")
        
        print(f"üîÆ Pr√©dictions selon X‚Éó(t+1) = A ¬∑ X‚Éó(t) ({horizon_days} jours)...")
        
        predictions = np.zeros((self.n_communes, horizon_days + 1))
        predictions[:, 0] = initial_state.flatten()
        
        current_state = initial_state.copy()
        
        # Application it√©rative : X‚Éó(t+1) = A ¬∑ X‚Éó(t)
        for day in range(1, horizon_days + 1):
            next_state = self.transition_matrix @ current_state
            
            # Pas de contraintes artificielles - juste le mod√®le math√©matique
            predictions[:, day] = next_state.flatten()
            current_state = next_state
        
        print("‚úÖ Pr√©dictions g√©n√©r√©es selon le mod√®le de Markov")
        
        return predictions
    
    def predict_by_commune(self, initial_cases: Dict[str, float], 
                          horizon_days: int = 14) -> Dict[str, List[float]]:
        """Interface pour pr√©dictions par commune"""
        initial_vector = np.zeros((self.n_communes, 1))
        for commune, cases in initial_cases.items():
            if commune in self.commune_to_index:
                idx = self.commune_to_index[commune]
                initial_vector[idx, 0] = cases
        
        predictions_matrix = self.predict(initial_vector, horizon_days)
        
        predictions_dict = {}
        for i, commune in enumerate(self.communes):
            predictions_dict[commune] = predictions_matrix[i, :].tolist()
        
        return predictions_dict
    
    def save_model(self, models: Dict, output_file: str = "data/matrix_markov_models.json"):
        """Sauvegarde selon votre mod√®le math√©matique"""
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        output_data = {
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "model_type": "markov_mathematical_formulation",
                "communes": self.communes,
                "mathematical_foundation": {
                    "state_equation": "X(t+1) = A * X(t) + Œµ(t)",
                    "estimation": "A = X(t+1) * X(t)^T * (X(t) * X(t)^T)^(-1)",
                    "constraints": "A_finale = (1-Œ±)*A_brute + Œ±*(A_brute‚äôG)",
                    "optimization": "Œ±* = argmin(Œ±) MAE_validation(Œ±)"
                }
            },
            "models": models
        }
        
        with open(output_file, 'w', encoding='utf8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Mod√®le math√©matique sauvegard√© : {output_file}")
    
    def generate_final_predictions(self, horizon_days: int = 14) -> Dict:
        """G√©n√®re les pr√©dictions finales selon votre mod√®le"""
        if self.transition_matrix is None:
            raise ValueError("Mod√®le non entra√Æn√©")
        
        print(f"üîÆ Pr√©dictions finales selon le mod√®le de Markov ({horizon_days} jours)...")
        
        # √âtat initial = derni√®res donn√©es liss√©es
        last_date = max(self.smoothed_data.keys())
        initial_cases = {}
        
        for commune in self.communes:
            if commune in self.smoothed_data[last_date]:
                initial_cases[commune] = self.smoothed_data[last_date][commune]
            else:
                initial_cases[commune] = 0.0
        
        # Pr√©dictions selon X‚Éó(t+1) = A ¬∑ X‚Éó(t)
        predictions = self.predict_by_commune(initial_cases, horizon_days)
        
        # Formatage avec dates
        last_date_obj = datetime.strptime(last_date, "%Y-%m-%d")
        
        predictions_formatted = {}
        for day in range(horizon_days + 1):
            prediction_date = (last_date_obj + timedelta(days=day)).strftime("%Y-%m-%d")
            predictions_formatted[prediction_date] = {}
            
            for commune in self.communes:
                predictions_formatted[prediction_date][commune] = predictions[commune][day]
        
        print("‚úÖ Pr√©dictions finales g√©n√©r√©es selon le mod√®le math√©matique")
        
        return {
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "base_date": last_date,
                "horizon_days": horizon_days,
                "communes": self.communes,
                "mathematical_model": "X(t+1) = A * X(t)"
            },
            "predictions": predictions_formatted
        }


def test_matrix_markov():
    """Test du mod√®le selon votre raisonnement math√©matique"""
    print("üß™ Test du mod√®le selon le raisonnement math√©matique...")
    print("üìã Impl√©mentation : X‚Éó(t+1) = A ¬∑ X‚Éó(t) + Œµ‚Éó(t)")
    
    try:
        # Initialisation
        model = MatrixMarkovModel()
        
        # Entra√Ænement selon votre optimisation
        models = model.train_model()
        
        if not models:
            print(Fore.RED + "‚ùå Entra√Ænement √©chou√©")
            return
        
        # Sauvegarde
        model.save_model(models)
        
        # Pr√©dictions finales
        predictions = model.generate_final_predictions(horizon_days=14)
        
        with open("data/matrix_predictions.json", 'w', encoding='utf8') as f:
            json.dump(predictions, f, indent=2, ensure_ascii=False)
        
        print("üíæ Pr√©dictions sauvegard√©es : data/matrix_predictions.json")
        
        # V√©rification du mod√®le
        best_alpha = models["metadata"]["best_alpha_geo"]
        best_model = models[f"alpha_geo_{best_alpha}"]
        
        A_finale = np.array(best_model["transition_matrix"])
        print(f"\nüìä Matrice A_finale :")
        print(f"   - Forme : {A_finale.shape}")
        print(f"   - Valeurs : [{np.min(A_finale):.3f}, {np.max(A_finale):.3f}]")
        
        # Test de pr√©diction
        print(f"\nüìã Exemple de pr√©dictions pour Bruxelles :")
        if "Bruxelles" in predictions["predictions"][list(predictions["predictions"].keys())[0]]:
            for i, (date, data) in enumerate(list(predictions["predictions"].items())[:5]):
                cases = data["Bruxelles"]
                print(f"   {date}: {cases:.2f} cas")
        
        print("‚úÖ Test selon le raisonnement math√©matique termin√© !")
        
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur : {e}")
        raise


if __name__ == "__main__":
    test_matrix_markov()